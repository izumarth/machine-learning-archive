# -*- coding: utf-8 -*-
"""Evaluation_Metrics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ghakqnpLSC78AqXCpZjsq4bgu1g7Qiqw
"""

pip install -U imbalanced-learn

pip install yellowbrick

import numpy as np
import pandas as pd

from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    classification_report,
)

from imblearn.datasets import fetch_datasets

from yellowbrick.classifier import (
    ClassificationReport,
    DiscriminationThreshold,
)

"""## Accuracy"""

# Load kdd
data = fetch_datasets()['protein_homo']

data = pd.concat([
    pd.DataFrame(data.data),
    pd.Series(data.target)
], axis=1)

col_names = [str(i) for i in range(74)] +['target']
data.columns = col_names

data.head()

data.shape

# imbalanced target
data.target.value_counts() / len(data)

# seperate train and test
X_train, X_test, y_train, y_test = train_test_split(
    data.drop(labels=['target'], axis=1),
    data['target'],
    test_size=0.3,
    random_state=42
)

X_train.shape, X_test.shape

# Baseline: majoirty class
y_train_base = pd.Series(np.full(len(y_train), -1))
y_test_base = pd.Series(np.full(len(y_test), -1))

# Train model
rf = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=2, n_jobs=4)

rf.fit(X_train, y_train)

y_train_rf = rf.predict_proba(X_train)[:,1]
y_test_rf = rf.predict_proba(X_test)[:,1]

lr = LogisticRegression(random_state=42, max_iter=1000)

lr.fit(X_train, y_train)

y_train_lr = lr.predict_proba(X_train)[:,1]
y_test_lr = lr.predict_proba(X_test)[:,1]

print(f"{accuracy_score(y_test, y_test_base)=}")
print(f"{accuracy_score(y_test, rf.predict(X_test))=}")
print(f"{accuracy_score(y_test, lr.predict(X_test))=}")

# minority classfied accuracy
def return_minority_perc(y_true, y_pred):
    minority_total = (y_test == 1).sum()
    minority_correct = np.sum(np.where((y_true==1)&(y_pred==1),1,0))
    return minority_correct / minority_total *100

print(f"{return_minority_perc(y_test, y_test_base)=}")
print(f"{return_minority_perc(y_test, rf.predict(X_test))=}")
print(f"{return_minority_perc(y_test, lr.predict(X_test))=}")

"""## Precision, Recall And F-measure

### Recall
- Recall: TP / (TP + FN)
  - Recall = TP / All real positves
- Precision: TP / (TP + FP)
  - Precision = TP / All Positive predictions

### F-measure
- (2 * Precsion * Recall) / (Precision + Recall)
"""

#Precision
print(f'Precision Baseline {precision_score(y_test, y_test_base)}')
print(f'Precision Randomforest {precision_score(y_test, rf.predict(X_test))}')
print(f'Precision Logistic Regression {precision_score(y_test, lr.predict(X_test))}')

#Recall
print(f'Precision Baseline {recall_score(y_test, y_test_base)}')
print(f'Precision Randomforest {recall_score(y_test, rf.predict(X_test))}')
print(f'Precision Logistic Regression {recall_score(y_test, lr.predict(X_test))}')

#F1 Score
print(f'Precision Baseline {f1_score(y_test, y_test_base, pos_label=1)}')
print(f'Precision Randomforest {f1_score(y_test, rf.predict(X_test), pos_label=1)}')
print(f'Precision Logistic Regression {f1_score(y_test, lr.predict(X_test), pos_label=1)}')

print(classification_report(y_test, rf.predict(X_test)))

print(classification_report(y_test, lr.predict(X_test)))

visualizer = DiscriminationThreshold(
    lr,
    n_trials=1,
    argmax='fscore',
    random_state=42,
    is_fitted='auto',
    exclude="queue_rate"
)

visualizer.fit(X_train, y_train)
visualizer.score(X_test, y_test)
visualizer.show()

visualizer = DiscriminationThreshold(
    rf,
    n_trials=1,
    argmax='fscore',
    random_state=42,
    is_fitted='auto',
    exclude="queue_rate"
)

visualizer.fit(X_train, y_train)
visualizer.score(X_test, y_test)
visualizer.show()



